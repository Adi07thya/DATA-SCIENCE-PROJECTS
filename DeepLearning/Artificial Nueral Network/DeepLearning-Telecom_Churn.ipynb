{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8AGWYh7Gf9q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2553,
     "status": "ok",
     "timestamp": 1591774228881,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "k_VNCUimHLDF",
    "outputId": "a0cf1519-e3b8-415d-95bc-7fd04bb77af3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID     MultipleLines  ... StreamingTV StreamingMovies\n",
       "0     7590-VHVEG  No phone service  ...          No              No\n",
       "1     5575-GNVDE                No  ...          No              No\n",
       "2     3668-QPYBK                No  ...          No              No\n",
       "3     7795-CFOCW  No phone service  ...          No              No\n",
       "4     9237-HQITU                No  ...          No              No\n",
       "...          ...               ...  ...         ...             ...\n",
       "7038  6840-RESVB               Yes  ...         Yes             Yes\n",
       "7039  2234-XADUH               Yes  ...         Yes             Yes\n",
       "7040  4801-JZAZL  No phone service  ...          No              No\n",
       "7041  8361-LTMKD               Yes  ...          No              No\n",
       "7042  3186-AJIEK                No  ...         Yes             Yes\n",
       "\n",
       "[7043 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/content/drive/My Drive/Untitled folder/Untitled Folder/churn_data.csv')\n",
    "\n",
    "df\n",
    "\n",
    "df1=pd.read_csv('/content/drive/My Drive/Untitled folder/Untitled Folder/customer_data.csv')\n",
    "\n",
    "df1\n",
    "\n",
    "df2=pd.read_csv('/content/drive/My Drive/Untitled folder/Untitled Folder/internet_data.csv')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2485,
     "status": "ok",
     "timestamp": 1591774228893,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "CVD0A-WjHP4S",
    "outputId": "71f85ee6-8dc2-431d-9bd6-10a3ea00a300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   tenure            7043 non-null   int64  \n",
      " 2   PhoneService      7043 non-null   object \n",
      " 3   Contract          7043 non-null   object \n",
      " 4   PaperlessBilling  7043 non-null   object \n",
      " 5   PaymentMethod     7043 non-null   object \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   object \n",
      " 8   Churn             7043 non-null   object \n",
      " 9   gender            7043 non-null   object \n",
      " 10  SeniorCitizen     7043 non-null   int64  \n",
      " 11  Partner           7043 non-null   object \n",
      " 12  Dependents        7043 non-null   object \n",
      " 13  MultipleLines     7043 non-null   object \n",
      " 14  InternetService   7043 non-null   object \n",
      " 15  OnlineSecurity    7043 non-null   object \n",
      " 16  OnlineBackup      7043 non-null   object \n",
      " 17  DeviceProtection  7043 non-null   object \n",
      " 18  TechSupport       7043 non-null   object \n",
      " 19  StreamingTV       7043 non-null   object \n",
      " 20  StreamingMovies   7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "## Merging the Dataframe\n",
    "\n",
    "df_new=df.merge(df1,how='inner',on='customerID')\n",
    "\n",
    "df_new\n",
    "\n",
    "df_new1=df_new.merge(df2,how='inner',on='customerID')\n",
    "\n",
    "df_new1\n",
    "\n",
    "df_new1.isnull().sum()\n",
    "\n",
    "df_new1.skew()\n",
    "\n",
    "df_new1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2442,
     "status": "ok",
     "timestamp": 1591774228897,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "zdSASf_VHUSx",
    "outputId": "ea66c37a-855e-4959-ff9e-47d1119b39b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>24</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.9</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.6</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  tenure PhoneService  ... TechSupport StreamingTV StreamingMovies\n",
       "0     7590-VHVEG       1           No  ...          No          No              No\n",
       "1     5575-GNVDE      34          Yes  ...          No          No              No\n",
       "2     3668-QPYBK       2          Yes  ...          No          No              No\n",
       "3     7795-CFOCW      45           No  ...         Yes          No              No\n",
       "4     9237-HQITU       2          Yes  ...          No          No              No\n",
       "...          ...     ...          ...  ...         ...         ...             ...\n",
       "7038  6840-RESVB      24          Yes  ...         Yes         Yes             Yes\n",
       "7039  2234-XADUH      72          Yes  ...          No         Yes             Yes\n",
       "7040  4801-JZAZL      11           No  ...          No          No              No\n",
       "7041  8361-LTMKD       4          Yes  ...          No          No              No\n",
       "7042  3186-AJIEK      66          Yes  ...         Yes         Yes             Yes\n",
       "\n",
       "[7043 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Label Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df_new1['Churn']=le.fit_transform(df_new1['Churn'])\n",
    "\n",
    "df_new1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1591774321318,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "IHE26qhnHYjI",
    "outputId": "96020840-35aa-4326-88a7-2e6ae268576a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   tenure            7043 non-null   int64  \n",
      " 2   PhoneService      7043 non-null   int64  \n",
      " 3   Contract          7043 non-null   int64  \n",
      " 4   PaperlessBilling  7043 non-null   int64  \n",
      " 5   PaymentMethod     7043 non-null   int64  \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   float64\n",
      " 8   Churn             7043 non-null   int64  \n",
      " 9   gender            7043 non-null   int64  \n",
      " 10  SeniorCitizen     7043 non-null   int64  \n",
      " 11  Partner           7043 non-null   int64  \n",
      " 12  Dependents        7043 non-null   int64  \n",
      " 13  MultipleLines     7043 non-null   int64  \n",
      " 14  InternetService   7043 non-null   object \n",
      " 15  OnlineSecurity    7043 non-null   object \n",
      " 16  OnlineBackup      7043 non-null   object \n",
      " 17  DeviceProtection  7043 non-null   object \n",
      " 18  TechSupport       7043 non-null   object \n",
      " 19  StreamingTV       7043 non-null   object \n",
      " 20  StreamingMovies   7043 non-null   object \n",
      "dtypes: float64(2), int64(11), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new1['TotalCharges']=pd.to_numeric(df_new1['TotalCharges'],errors='coerce')\n",
    "df_new1.info()\n",
    "df_new1.isnull().sum()\n",
    "df_new1['TotalCharges'].fillna(value=df_new1['TotalCharges'].mean(),inplace=True)\n",
    "\n",
    "df_new1['PhoneService']=le.fit_transform(df_new1['PhoneService'])\n",
    "df_new1['Contract']=le.fit_transform(df_new1['Contract'])\n",
    "df_new1['PaperlessBilling']=le.fit_transform(df_new1['PaperlessBilling'])\n",
    "df_new1['PaymentMethod']=le.fit_transform(df_new1['PaymentMethod'])\n",
    "df_new1['gender']=le.fit_transform(df_new1['gender'])\n",
    "df_new1['Partner']=le.fit_transform(df_new1['Partner'])\n",
    "df_new1['Dependents']=le.fit_transform(df_new1['Dependents'])\n",
    "df_new1['MultipleLines']=le.fit_transform(df_new1['MultipleLines'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1788,
     "status": "ok",
     "timestamp": 1591774321331,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "2OjKwR7eHbjO",
    "outputId": "0e3745c6-5212-4d58-8674-c76eac5ec4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 27 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   tenure                                7043 non-null   int64  \n",
      " 1   PhoneService                          7043 non-null   int64  \n",
      " 2   Contract                              7043 non-null   int64  \n",
      " 3   PaperlessBilling                      7043 non-null   int64  \n",
      " 4   PaymentMethod                         7043 non-null   int64  \n",
      " 5   MonthlyCharges                        7043 non-null   float64\n",
      " 6   TotalCharges                          7043 non-null   float64\n",
      " 7   Churn                                 7043 non-null   int64  \n",
      " 8   gender                                7043 non-null   int64  \n",
      " 9   SeniorCitizen                         7043 non-null   int64  \n",
      " 10  Partner                               7043 non-null   int64  \n",
      " 11  Dependents                            7043 non-null   int64  \n",
      " 12  MultipleLines                         7043 non-null   int64  \n",
      " 13  InternetService_Fiber optic           7043 non-null   uint8  \n",
      " 14  InternetService_No                    7043 non-null   uint8  \n",
      " 15  OnlineSecurity_No internet service    7043 non-null   uint8  \n",
      " 16  OnlineSecurity_Yes                    7043 non-null   uint8  \n",
      " 17  OnlineBackup_No internet service      7043 non-null   uint8  \n",
      " 18  OnlineBackup_Yes                      7043 non-null   uint8  \n",
      " 19  DeviceProtection_No internet service  7043 non-null   uint8  \n",
      " 20  DeviceProtection_Yes                  7043 non-null   uint8  \n",
      " 21  TechSupport_No internet service       7043 non-null   uint8  \n",
      " 22  TechSupport_Yes                       7043 non-null   uint8  \n",
      " 23  StreamingTV_No internet service       7043 non-null   uint8  \n",
      " 24  StreamingTV_Yes                       7043 non-null   uint8  \n",
      " 25  StreamingMovies_No internet service   7043 non-null   uint8  \n",
      " 26  StreamingMovies_Yes                   7043 non-null   uint8  \n",
      "dtypes: float64(2), int64(11), uint8(14)\n",
      "memory usage: 866.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tenure                                  0.239540\n",
       "PhoneService                           -2.727153\n",
       "Contract                                0.630959\n",
       "PaperlessBilling                       -0.375396\n",
       "PaymentMethod                          -0.170129\n",
       "MonthlyCharges                         -0.220524\n",
       "TotalCharges                            0.962394\n",
       "Churn                                   1.063031\n",
       "gender                                 -0.019031\n",
       "SeniorCitizen                           1.833633\n",
       "Partner                                 0.067922\n",
       "Dependents                              0.875199\n",
       "MultipleLines                           0.118719\n",
       "InternetService_Fiber optic             0.243494\n",
       "InternetService_No                      1.375769\n",
       "OnlineSecurity_No internet service      1.375769\n",
       "OnlineSecurity_Yes                      0.943722\n",
       "OnlineBackup_No internet service        1.375769\n",
       "OnlineBackup_Yes                        0.652817\n",
       "DeviceProtection_No internet service    1.375769\n",
       "DeviceProtection_Yes                    0.657450\n",
       "TechSupport_No internet service         1.375769\n",
       "TechSupport_Yes                         0.924630\n",
       "StreamingTV_No internet service         1.375769\n",
       "StreamingTV_Yes                         0.475581\n",
       "StreamingMovies_No internet service     1.375769\n",
       "StreamingMovies_Yes                     0.460199\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1\n",
    "\n",
    "final=df_new1.drop('customerID',1)\n",
    "\n",
    "final\n",
    "\n",
    "d1=pd.get_dummies(final,drop_first=True)\n",
    "\n",
    "d1\n",
    "\n",
    "d1.info()\n",
    "\n",
    "d1.skew()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nXKvrMYHfYy"
   },
   "outputs": [],
   "source": [
    "\n",
    "y=d1['Churn'].values\n",
    "x=d1.drop('Churn',1).values\n",
    "\n",
    "## Training the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7003,
     "status": "ok",
     "timestamp": 1591774542834,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "bKi691uHJNg2",
    "outputId": "07a9e9b5-f9b1-4f10-8a69-97a7e81fbf30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.2.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: protobuf, gast, astunparse, grpcio, keras-preprocessing, absl-py, six, h5py, scipy, google-pasta, termcolor, tensorboard, opt-einsum, tensorflow-estimator, wrapt, numpy, wheel\n",
      "Required-by: fancyimpute\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHmJ77vBKdX_"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1754,
     "status": "ok",
     "timestamp": 1591774786022,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "y3R8pOIgKooL",
    "outputId": "48609227-1384-49d1-cee7-51c3be2cc1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1591774827479,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "yHoE8B7CLAKW",
    "outputId": "f8d7a669-267b-4851-ab3a-74ea1dcc1273"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282,)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODHDpkjrLRzC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5cPmybBLGag"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(units=26,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=13,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133689,
     "status": "ok",
     "timestamp": 1591775101005,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "y77VeZCTLbIo",
    "outputId": "824e488d-875d-4ba8-ee69-71cf5763f304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 4.6526 - val_loss: 0.5285\n",
      "Epoch 2/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 1.0090 - val_loss: 1.8581\n",
      "Epoch 3/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 1.6141 - val_loss: 1.7385\n",
      "Epoch 4/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8069 - val_loss: 0.7744\n",
      "Epoch 5/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6958 - val_loss: 0.5563\n",
      "Epoch 6/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6744 - val_loss: 0.5647\n",
      "Epoch 7/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8973 - val_loss: 3.4652\n",
      "Epoch 8/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.9366 - val_loss: 5.4520\n",
      "Epoch 9/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 1.4308 - val_loss: 1.0484\n",
      "Epoch 10/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6595 - val_loss: 0.9492\n",
      "Epoch 11/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6935 - val_loss: 0.8756\n",
      "Epoch 12/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8528 - val_loss: 0.4792\n",
      "Epoch 13/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8734 - val_loss: 1.4224\n",
      "Epoch 14/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8990 - val_loss: 0.9939\n",
      "Epoch 15/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7076 - val_loss: 0.7007\n",
      "Epoch 16/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8049 - val_loss: 1.6759\n",
      "Epoch 17/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5998 - val_loss: 0.7733\n",
      "Epoch 18/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7194 - val_loss: 0.8752\n",
      "Epoch 19/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7392 - val_loss: 0.5144\n",
      "Epoch 20/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6329 - val_loss: 2.0990\n",
      "Epoch 21/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8612 - val_loss: 3.3166\n",
      "Epoch 22/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6665 - val_loss: 0.5579\n",
      "Epoch 23/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8411 - val_loss: 0.8431\n",
      "Epoch 24/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6579 - val_loss: 0.7631\n",
      "Epoch 25/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6285 - val_loss: 0.7046\n",
      "Epoch 26/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6855 - val_loss: 0.4992\n",
      "Epoch 27/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5156 - val_loss: 0.4849\n",
      "Epoch 28/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6148 - val_loss: 0.6457\n",
      "Epoch 29/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5693 - val_loss: 0.4819\n",
      "Epoch 30/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6445 - val_loss: 1.1433\n",
      "Epoch 31/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6716 - val_loss: 2.3905\n",
      "Epoch 32/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6310 - val_loss: 0.5411\n",
      "Epoch 33/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5646 - val_loss: 0.6676\n",
      "Epoch 34/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5968 - val_loss: 0.5996\n",
      "Epoch 35/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6793 - val_loss: 1.4025\n",
      "Epoch 36/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8019 - val_loss: 0.5842\n",
      "Epoch 37/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5423 - val_loss: 0.7366\n",
      "Epoch 38/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5618 - val_loss: 0.7684\n",
      "Epoch 39/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5621 - val_loss: 0.8850\n",
      "Epoch 40/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6129 - val_loss: 0.5043\n",
      "Epoch 41/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5524 - val_loss: 0.8579\n",
      "Epoch 42/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7109 - val_loss: 1.4511\n",
      "Epoch 43/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.9358 - val_loss: 0.5810\n",
      "Epoch 44/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6286 - val_loss: 0.9679\n",
      "Epoch 45/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7200 - val_loss: 0.5108\n",
      "Epoch 46/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5832 - val_loss: 0.4470\n",
      "Epoch 47/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7689 - val_loss: 0.9195\n",
      "Epoch 48/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5732 - val_loss: 0.8397\n",
      "Epoch 49/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6141 - val_loss: 1.4503\n",
      "Epoch 50/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6693 - val_loss: 0.6705\n",
      "Epoch 51/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6041 - val_loss: 0.6025\n",
      "Epoch 52/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6282 - val_loss: 0.4257\n",
      "Epoch 53/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5846 - val_loss: 0.5520\n",
      "Epoch 54/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5451 - val_loss: 0.4802\n",
      "Epoch 55/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5605 - val_loss: 0.4475\n",
      "Epoch 56/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5810 - val_loss: 1.1697\n",
      "Epoch 57/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6381 - val_loss: 0.4549\n",
      "Epoch 58/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6051 - val_loss: 0.5987\n",
      "Epoch 59/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5454 - val_loss: 0.5706\n",
      "Epoch 60/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5243 - val_loss: 0.8066\n",
      "Epoch 61/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7572 - val_loss: 0.8270\n",
      "Epoch 62/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7381 - val_loss: 0.4839\n",
      "Epoch 63/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6881 - val_loss: 0.5875\n",
      "Epoch 64/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5743 - val_loss: 0.4928\n",
      "Epoch 65/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5932 - val_loss: 0.5824\n",
      "Epoch 66/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6462 - val_loss: 0.4312\n",
      "Epoch 67/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5424 - val_loss: 0.7527\n",
      "Epoch 68/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5952 - val_loss: 0.5996\n",
      "Epoch 69/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6043 - val_loss: 0.4732\n",
      "Epoch 70/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.6106 - val_loss: 0.5687\n",
      "Epoch 71/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5512 - val_loss: 0.8774\n",
      "Epoch 72/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6045 - val_loss: 0.4193\n",
      "Epoch 73/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5295 - val_loss: 0.7161\n",
      "Epoch 74/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5375 - val_loss: 0.4568\n",
      "Epoch 75/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5294 - val_loss: 0.4234\n",
      "Epoch 76/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6019 - val_loss: 1.7442\n",
      "Epoch 77/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6763 - val_loss: 0.4304\n",
      "Epoch 78/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5308 - val_loss: 0.7504\n",
      "Epoch 79/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6534 - val_loss: 1.2491\n",
      "Epoch 80/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6414 - val_loss: 0.4211\n",
      "Epoch 81/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5903 - val_loss: 0.4660\n",
      "Epoch 82/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5920 - val_loss: 0.6085\n",
      "Epoch 83/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6359 - val_loss: 0.9120\n",
      "Epoch 84/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5983 - val_loss: 0.4289\n",
      "Epoch 85/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5692 - val_loss: 0.4341\n",
      "Epoch 86/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5102 - val_loss: 0.5909\n",
      "Epoch 87/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4688 - val_loss: 0.4138\n",
      "Epoch 88/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5345 - val_loss: 0.4238\n",
      "Epoch 89/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5130 - val_loss: 0.4223\n",
      "Epoch 90/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5292 - val_loss: 2.3747\n",
      "Epoch 91/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.8188 - val_loss: 0.4185\n",
      "Epoch 92/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4684 - val_loss: 0.4553\n",
      "Epoch 93/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4946 - val_loss: 0.5264\n",
      "Epoch 94/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5164 - val_loss: 0.4135\n",
      "Epoch 95/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4918 - val_loss: 0.4546\n",
      "Epoch 96/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5938 - val_loss: 0.4175\n",
      "Epoch 97/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5082 - val_loss: 0.4382\n",
      "Epoch 98/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5120 - val_loss: 0.4907\n",
      "Epoch 99/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5256 - val_loss: 0.4249\n",
      "Epoch 100/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7044 - val_loss: 0.5038\n",
      "Epoch 101/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4958 - val_loss: 0.9021\n",
      "Epoch 102/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4862 - val_loss: 0.4757\n",
      "Epoch 103/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 0.5282\n",
      "Epoch 104/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4783 - val_loss: 0.4830\n",
      "Epoch 105/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5397 - val_loss: 0.4182\n",
      "Epoch 106/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7716 - val_loss: 0.7211\n",
      "Epoch 107/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5404 - val_loss: 0.5212\n",
      "Epoch 108/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4793 - val_loss: 1.0415\n",
      "Epoch 109/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4966 - val_loss: 0.4373\n",
      "Epoch 110/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5199 - val_loss: 0.4562\n",
      "Epoch 111/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4782 - val_loss: 0.5503\n",
      "Epoch 112/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5111 - val_loss: 0.4363\n",
      "Epoch 113/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4805 - val_loss: 0.4646\n",
      "Epoch 114/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5075 - val_loss: 1.8918\n",
      "Epoch 115/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6323 - val_loss: 0.5256\n",
      "Epoch 116/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5478 - val_loss: 1.3058\n",
      "Epoch 117/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5472 - val_loss: 0.4988\n",
      "Epoch 118/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4900 - val_loss: 0.4126\n",
      "Epoch 119/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4540 - val_loss: 0.4126\n",
      "Epoch 120/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5597 - val_loss: 0.5746\n",
      "Epoch 121/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4637 - val_loss: 2.9564\n",
      "Epoch 122/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6478 - val_loss: 0.4702\n",
      "Epoch 123/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4652 - val_loss: 0.5516\n",
      "Epoch 124/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5110 - val_loss: 0.5648\n",
      "Epoch 125/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.6033 - val_loss: 0.5439\n",
      "Epoch 126/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5058 - val_loss: 0.4501\n",
      "Epoch 127/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4964 - val_loss: 0.6289\n",
      "Epoch 128/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5100 - val_loss: 0.5576\n",
      "Epoch 129/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4948 - val_loss: 0.5721\n",
      "Epoch 130/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5226 - val_loss: 0.5434\n",
      "Epoch 131/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5072 - val_loss: 0.4654\n",
      "Epoch 132/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.5018 - val_loss: 0.7230\n",
      "Epoch 133/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5976 - val_loss: 0.4574\n",
      "Epoch 134/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4455 - val_loss: 0.5522\n",
      "Epoch 135/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5027 - val_loss: 0.5480\n",
      "Epoch 136/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5044 - val_loss: 1.0191\n",
      "Epoch 137/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4838 - val_loss: 0.4683\n",
      "Epoch 138/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4835 - val_loss: 0.4254\n",
      "Epoch 139/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5588 - val_loss: 0.5553\n",
      "Epoch 140/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4926 - val_loss: 0.4143\n",
      "Epoch 141/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4677 - val_loss: 0.7250\n",
      "Epoch 142/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5577 - val_loss: 0.6077\n",
      "Epoch 143/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5404 - val_loss: 0.7600\n",
      "Epoch 144/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5383 - val_loss: 0.4591\n",
      "Epoch 145/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4900 - val_loss: 0.6689\n",
      "Epoch 146/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4447 - val_loss: 0.4191\n",
      "Epoch 147/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4823 - val_loss: 0.6499\n",
      "Epoch 148/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4681 - val_loss: 0.4771\n",
      "Epoch 149/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4945 - val_loss: 0.4451\n",
      "Epoch 150/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5374 - val_loss: 0.5070\n",
      "Epoch 151/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4708 - val_loss: 0.6539\n",
      "Epoch 152/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5457 - val_loss: 0.4135\n",
      "Epoch 153/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5016 - val_loss: 0.7903\n",
      "Epoch 154/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4491 - val_loss: 0.7822\n",
      "Epoch 155/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4601 - val_loss: 0.5463\n",
      "Epoch 156/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5010 - val_loss: 0.4144\n",
      "Epoch 157/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4410 - val_loss: 0.4483\n",
      "Epoch 158/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4630 - val_loss: 0.4135\n",
      "Epoch 159/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4588 - val_loss: 0.4766\n",
      "Epoch 160/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4428 - val_loss: 0.4836\n",
      "Epoch 161/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5192 - val_loss: 0.4443\n",
      "Epoch 162/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4948 - val_loss: 0.4429\n",
      "Epoch 163/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4739 - val_loss: 0.4180\n",
      "Epoch 164/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4866 - val_loss: 0.6709\n",
      "Epoch 165/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4849 - val_loss: 0.4405\n",
      "Epoch 166/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5521 - val_loss: 0.4189\n",
      "Epoch 167/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4474 - val_loss: 0.4731\n",
      "Epoch 168/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4638 - val_loss: 0.4425\n",
      "Epoch 169/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4758 - val_loss: 0.5429\n",
      "Epoch 170/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4525 - val_loss: 0.4613\n",
      "Epoch 171/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4611 - val_loss: 0.6520\n",
      "Epoch 172/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4960 - val_loss: 0.4277\n",
      "Epoch 173/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4455 - val_loss: 0.6018\n",
      "Epoch 174/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5431 - val_loss: 0.4140\n",
      "Epoch 175/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4489 - val_loss: 0.4320\n",
      "Epoch 176/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4400 - val_loss: 0.4669\n",
      "Epoch 177/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4560 - val_loss: 0.8940\n",
      "Epoch 178/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4678 - val_loss: 0.6815\n",
      "Epoch 179/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4667 - val_loss: 0.5057\n",
      "Epoch 180/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4452 - val_loss: 0.8197\n",
      "Epoch 181/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4599 - val_loss: 0.5276\n",
      "Epoch 182/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5062 - val_loss: 1.0997\n",
      "Epoch 183/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4559 - val_loss: 0.5104\n",
      "Epoch 184/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4588 - val_loss: 0.4140\n",
      "Epoch 185/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4411 - val_loss: 0.4493\n",
      "Epoch 186/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4696 - val_loss: 0.5635\n",
      "Epoch 187/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4458 - val_loss: 0.6480\n",
      "Epoch 188/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6541 - val_loss: 0.4561\n",
      "Epoch 189/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4443 - val_loss: 0.4295\n",
      "Epoch 190/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4453 - val_loss: 0.4572\n",
      "Epoch 191/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4368 - val_loss: 0.5685\n",
      "Epoch 192/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4477 - val_loss: 0.4415\n",
      "Epoch 193/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4425 - val_loss: 0.5490\n",
      "Epoch 194/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4415 - val_loss: 0.5632\n",
      "Epoch 195/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4415 - val_loss: 0.4216\n",
      "Epoch 196/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4391 - val_loss: 0.5034\n",
      "Epoch 197/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4441 - val_loss: 0.4275\n",
      "Epoch 198/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4492 - val_loss: 0.5936\n",
      "Epoch 199/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4865 - val_loss: 0.4185\n",
      "Epoch 200/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4348 - val_loss: 0.4466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f057a0b7e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=200,\n",
    "          validation_data=(x_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2089,
     "status": "ok",
     "timestamp": 1591775178934,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "wLQUvwzRMLbS",
    "outputId": "78298f5a-598e-400c-f5a4-2b2ca02388dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f05d59e1908>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd3gc1dm+77NNXZZly0WWO8bG3WBK6C20AA4hgRBIIL8kEJJAei9fwkeSLyEhlUAIvQUIkNBCx2CMsXFB7r3Llq1u1e3n98eZ2V2t2qqsNELvfV26drU7mj2anXnmmee854zSWiMIgiA4F9dAN0AQBEHoHBFqQRAEhyNCLQiC4HBEqAVBEByOCLUgCILD8aRjpSNHjtSTJk1Kx6oFQRA+lKxevbpKa13U3ntpEepJkyaxatWqdKxaEAThQ4lSam9H70n0IQiC4HBEqAVBEByOCLUgCILDSUtGLQjC0CMUClFWVobf7x/opjiazMxMSkpK8Hq9Kf+NCLUgCH1CWVkZeXl5TJo0CaXUQDfHkWitqa6upqysjMmTJ6f8dxJ9CILQJ/j9fkaMGCEi3QlKKUaMGNHtqw4RakEQ+gwR6a7pyTYanEIdjcCah82jIAjCh5zBKdT7lsNzX4P9Kwa6JYIgOIjc3NyBbkJaGJxCHW4xj5HQwLZDEAShHxicQh0Jm0ct0YcgCG3RWvPd736X2bNnM2fOHJ544gkAysvLOf3005k/fz6zZ8/mnXfeIRKJcN1118WW/cMf/jDArW/L4CzPi1pOWkcHth2CILTLL57fyKaD9X26zpnF+fzPJbNSWvaZZ56htLSUtWvXUlVVxfHHH8/pp5/OY489xvnnn8+Pf/xjIpEIzc3NlJaWcuDAATZs2ABAXV1dn7a7LxikjtoWarnfoyAIbVm6dClXXXUVbreb0aNHc8YZZ7By5UqOP/547r//fn7+85+zfv168vLymDJlCrt27eKmm27i5ZdfJj8/f6Cb34ZB6qit6EOqPgTBkaTqfPub008/nSVLlvDiiy9y3XXX8a1vfYvPfe5zrF27lldeeYW77rqLJ598kvvuu2+gm9qKQeqog+ZRog9BENrhtNNO44knniASiVBZWcmSJUs44YQT2Lt3L6NHj+ZLX/oSX/ziF1mzZg1VVVVEo1Euv/xybr31VtasWTPQzW/D4HTUEcmoBUHomMsuu4z33nuPefPmoZTit7/9LWPGjOHBBx/ktttuw+v1kpuby0MPPcSBAwf4/Oc/TzRq9OTXv/71ALe+LYNTqO3oQ4RaEIQEGhsbATP677bbbuO2225r9f61117Ltdde2+bvnOiiExmk0YftqCWjFgThw8/gFGopzxMEYQgxOIVayvMEQRhCDE6hloxaEIQhxOAUattRSx21IAhDgMEp1JJRC4IwhEipPE8ptQdoACJAWGu9MJ2N6pKIRB+CIAwduuOoz9Jazx9wkQZx1IIg9JrO5q7es2cPs2fP7sfWdM7gjD6kjloQhCFEqiMTNfCqUkoDf9da3528gFLqeuB6gAkTJvRdC9tDHLUgOJuXfgCH1vftOsfMgQv/r8O3f/CDHzB+/Hi++tWvAvDzn/8cj8fD4sWLqa2tJRQKceutt7Jo0aJufazf7+fGG29k1apVeDwebr/9ds466yw2btzI5z//eYLBINFolKeffpri4mKuuOIKysrKiEQi/PSnP+XKK6/s1b8NqQv1qVrrA0qpUcBrSqktWusliQtY4n03wMKFC9Nb4BzLqKWOWhAEw5VXXsk3vvGNmFA/+eSTvPLKK9x8883k5+dTVVXFSSedxKWXXtqtG8zecccdKKVYv349W7Zs4bzzzmPbtm3cddddfP3rX+fqq68mGAwSiUT473//S3FxMS+++CIAR44c6ZP/LSWh1lofsB4rlFL/Bk4AlnT+V2kkKuV5guBoOnG+6WLBggVUVFRw8OBBKisrGT58OGPGjOGb3/wmS5YsweVyceDAAQ4fPsyYMWNSXu/SpUu56aabAJgxYwYTJ05k27ZtfOQjH+GXv/wlZWVlfOITn2DatGnMmTOHb3/723z/+9/n4osv5rTTTuuT/63LjFoplaOUyrOfA+cBG/rk03uKzJ4nCEI7fOpTn+Kpp57iiSee4Morr+TRRx+lsrKS1atXU1payujRo/H7/X3yWZ/5zGd47rnnyMrK4qKLLuLNN9/k6KOPZs2aNcyZM4ef/OQn3HLLLX3yWak46tHAv61LBQ/wmNb65T759J4iIxMFQWiHK6+8ki996UtUVVXx9ttv8+STTzJq1Ci8Xi+LFy9m79693V7naaedxqOPPsrZZ5/Ntm3b2LdvH9OnT2fXrl1MmTKFm2++mX379rFu3TpmzJhBYWEh11xzDQUFBdxzzz198n91KdRa613AvD75tL5CHLUgCO0wa9YsGhoaGDduHGPHjuXqq6/mkksuYc6cOSxcuJAZM2Z0e51f+cpXuPHGG5kzZw4ej4cHHniAjIwMnnzySR5++GG8Xi9jxozhRz/6EStXruS73/0uLpcLr9fLnXfe2Sf/l9Jp6JBbuHChXrVqVZ+vN8ZDi2DXW3Duz+HUb6bvcwRBSJnNmzdzzDHHDHQzBgXtbSul1OqOxqkM0jpqiT4EQRg6DNI7vEj0IQhC71m/fj2f/exnW72WkZHBihUrBqhF7TM4hVrmoxYER6K17laN8kAzZ84cSktL+/UzexI3D87oQ+qoBcFxZGZmUl1d3SMhGiporamuriYzM7NbfzdIHbVk1ILgNEpKSigrK6OysnKgm+JoMjMzKSkp6dbfOEqod1c1kZfpYWRuRucLSkYtCI7D6/UyefLkgW7GhxJHRR8X/mkJdy/Z1fWCUkctCMIQwlFC7VaKaDSFfCs2MlEyakEQPvw4SqhdShFJpSNCHLUgCEMIZwm1K1VHLeV5giAMHRwl1G5Xqo7aij6kPE8QhCGAo4TapRSpGGqp+hAEYSjhMKEmtehDMmpBEIYQjhJqt0sR6Uqoo9F4tYcItSAIQwBHCXVKVR927AFSnicIwpDAUULtdqmuCzkiiUItjloQhA8/jhJqlyKF6EOEWhCEoYWzhDqV8jy7NA+kjloQhCGBo4Q6pSHkiY5a6qgFQRgCOEuoXYpol45aog9BEIYWjhJqpRSRrrQ3mhh9iFALgvDhx1FC7XYhjloQBCEJZwm1SmXAi9RRC4IwtHCUULskoxYEQWiDs4RapSDUUSnPEwRhaOEooU4p+hBHLQjCEMNRQu1y0fU0p1JHLQjCEMNZQp3KgJeIlOcJgjC0cJRQp3SHF9tRK7cItSAIQ4KUhVop5VZKfaCUeiFtjUnJUVtC7cmQ8jxBEIYE3XHUXwc2p6shYA8h72Ih21G7feKoBUEYEqQk1EqpEuBjwD1pbUwq05zaGbUnU8rzBEEYEqTqqP8IfA/o0MIqpa5XSq1SSq2qrKzsWWNSqqO2ow9x1IIgDA26FGql1MVAhdZ6dWfLaa3v1lov1FovLCoq6lFjUrpnop1RuzOkPE8QhCFBKo76FOBSpdQe4HHgbKXUI2lpTCpDyKOJ0Yc4akEQPvx0KdRa6x9qrUu01pOATwNvaq2vSUtjVAqdiRGJPgRBGFo4q466O/dMdGeIUAuCMCTwdGdhrfVbwFtpaQnWPRNTrqP2QagpXU0RBEFwDA5z1AqdakYtjloQhCGCo4TapVK5C3kIlAvcXqmjFgRhSOAsoXalcs/EELi8oJQ4akEQhgSOEurU7pkYNm5auaSOWhCEIYGzhDrVkYkujxFqcdSCIAwBHCXUKtU7vLi9Ms2pIAhDBkcJtduVwjSnsYzaJdOcCoIwJHCcUHdd9REGt0QfgiAMHRwl1CkNIW/lqKU8TxCEDz8OE2pSu8OL22vuhCuOWhCEIYCjhDq16CPBUUt5niAIQwBHCbVLKbSm82Hk0ZBk1IIgDCkcJdRulwLoPKeOhMz9EqU8TxCEIYKjhNrS6c5rqaPhhM5EEWpBED78OEuoY466E6GOJEYfklELgvDhx1FC7VYpCHU0nDCEXMrzBEH48OMsobYcdafRh44YoXZJRi0IwtDAUUKtbEfdmf5GI6YjUaY5FQRhiOAooXbbnYmdRh8R46aljloQhCGCs4Q6lc7EaDgu1OKoBUEYAjhKqOPRRxcZtXL3bR113X54/uvxG+cKgiA4CEcJdawzMeWqjz6KPnYthtUPQN2+vlmfIAhCH+IsoVYpVH1Eo/HoA/qmRC8csNYlUYogCM7DUUJtD3jpVHt1JEmo+0Bcw37zGA33fl2CIAh9jLOEOtUh5MptpjmFPhZqqSIRBMF5OEqoU8uoI/GM2v69t4TEUQuC4FwcJdSuVKo+oumMPsRRC4LgPBwl1ClNc2oPIVdu6/e+EGq7M1GEWhAE5+EooU49o3ZJZ6IgCEMGhwl1KiMTk6OPPnDBEn0IguBguhRqpVSmUup9pdRapdRGpdQv0tWYbs2e16d11OKoBUFwLp4UlgkAZ2utG5VSXmCpUuolrfXyvm5MlzcO0NpEHcptXDX0bUYtjloQBAfSpVBrc6fZRutXr/WTlhn7u4w+bCF1ecw0p9C3GbV0JgqC4EBSyqiVUm6lVClQAbymtV7RzjLXK6VWKaVWVVZW9qgx8SHkHSxgRxMuV9/WUccctUQfgiA4j5SEWmsd0VrPB0qAE5RSs9tZ5m6t9UKt9cKioqKeNcZqTYcZtU501H1Y9RFqMY8SfQjpov4gvHeH3D5O6BHdqvrQWtcBi4EL0tEY21HrDqMPy/Ha05xCH2fU4qiFNLH5eXjlR9BcPdAtEQYhqVR9FCmlCqznWcBHgS1paUxXQ8hjGbWU5wmDDHuuczEDQg9IpepjLPCgUsqNEfYntdYvpKMxrq6mOY2mKfqQkYlCuomKUAs9J5Wqj3XAgn5oS9e34rKFtNXIRKmjFgYB9r4l+5jQAxw1MtHd1V3IEx11n9ZRi1ALacbedyVeE3qAo4RadXUX8lh5nju+cG93fK0loxbSjzhqoRc4Sqhj0Ud/ludFgvHnItRCuhChFnqBM4W6o9jZFlLVh/NR224apDNRSB8i1EIvcJRQx6o+UirP66OM2q74ADmIhPQREaEWeo7DhNo8dhh9tMqo+6iO2h6VmLh+QehrYo5artqE7uMooe5ymlOdjugj0VHLQSSkCYk+hF7gKKHu1ux5sfK8XtZRJ2bUItRCuhChFnqBo4S6ywEvrTLqPprmNNFRS2eikC5iddQi1EL3SWUIeb/h6mqaU50g1Da9dcGtHLUcREKaiA0hFzMgdB9nCbU9zWkqs+fZ9y7oy/I8EWohXUj0IfQCRwl119OcJmTUtkD3qVCL2xHShAi10AucJdRdVX0klufZ+ixVH8JgQDJqoRc4SqhVV9Oc2qKs3KDs6EMyamEQIHXUQi8YZFUf7Q14kSHkwiBAbhwg9AJHOerYNKddzfXhcidk1L2sow5ZQu3NkYNISB+SUQu9wFGOOjbNaUqz5/XRNKe2o/ZldzIRtiD0EsmohV7gKKHucprTVje37eMh5N6snh9Eu5dAoLF37RA+3IijFnqBs4S6y9nzLFHuy/mow37wZILL27ODqKUWHrwU1j/Zu3YIXbP0D7D+qYFuRc+QzkShFzhKqF1dzkdtdya6+nCaU1uo3T3rTAw2Adp6FNLKmodh038GuhU9Q25uK/QCRwk1mKlOu3eHlz7IqD2ZZp09OYjs6CTxTjFCeoiG4vM6DzYkoxZ6geOE2u1SqQ0h78uM2pNhDaLpwbrszsjBKiCDiUg47kwHG5JRC73AcULtUqqTzsSE8ry+nObUk2nEv0eO2r4x7iAVkMFENBSvRx5sSEYt9ALHCbXbpToe8KLT0ZkYAK9EH4OCSGjwOlJx1EIvcNSAFzCOusNpTmPRh6vv6qhDLcZRQ8/ybok++o9oeBA7amvfGqztFwYUBwp1ind46euMOhrpmeiLo+4/IqHBGzHJEHKhFzgy+khp9rx0lOdJRu1sIsHB60gloxZ6gSOFuuOMOl2O2u5M7I2jFqeUVqIRQA9ioZbyPKHnOE6olepEqO2dvVV53kDXUdsZtUQfaSUWHQxWoZbORKHnOE6o3aqz6CPx5rZ9OYTc1/ORibajHqwCMliwt+9gvXIRoRZ6QZdCrZQar5RarJTapJTaqJT6ejobZKKPDt6MhuMVH31VRx0JJjjq3lR9iFCnlUHvqOXmtkLPSaXqIwx8W2u9RimVB6xWSr2mtd6Ujga5XF0MIbc7EW1H3etpToPg9vWiM9HOqAepgAwW7O9mMG7naDR+5SeOWugBXTpqrXW51nqN9bwB2AyMS1uDVGdDyCPG+UK8jrq30UckCG5vLzoTpeqjXxjMjjoxUhOhFnpAtzJqpdQkYAGwIh2NgRQyaleSo+6NUGttCXVGH4xMHIQCMpgYzBl14n4lQi30gJSFWimVCzwNfENrXd/O+9crpVYppVZVVlb2vEEu1XHsrBOFug/qqKNhQMejj16NTBShTiu2QA9GRy1CLfSSlIRaKeXFiPSjWutn2ltGa3231nqh1nphUVFRjxvUuaMOt82oe1OeZ5fUub1WRt0boZbyvLQSc9Sh3ncg9zeJJ3HpTBR6QCpVHwq4F9istb493Q1SqrM7vPRx9GGLq6cPoo/B6PQGE7EToR58YheVjFroHak46lOAzwJnK6VKrZ+L0tUgt6uzaU7D8c5EVx9EH7bT6YvOxMGYnQ4mErevU06KIT88+imo2NL5chJ9CL2ky/I8rfVSQPVDWwAYQR0nN3wAemG8siPWmGg70UcvLoNtN+z2yTSnTidRnCMhczPigab+AGx/FY65BEbN6Hg5EWqhlzhuZOJpgXf4QvXv4eAHbd9sL/rozWVwLKP29T6jdorL+7DSKud1iNjZJ2n7sSNaCfUgi20ER+A4oc7E2uk3P9f2zWg4Qaj7oI46Fn30wRByqfpIL8mO2glEUhVqyaiF3uE4ofYpa0fe9GzbWEMnDHgBE4P0Sqj7IvqQ8rx+wYkZddi6Iot0JdQOvBoQBhWOE+oMbe38Nbvg8MbWbyaW54GJP/rKUfd6mlOHiMeHlUHtqCWjFnqH44TaR5gw1nzTm59v/WY0muSoXX1TR+2xHLWOdL9zUjLqttTsgl+Ph+qdfbdOR2bU1v6TqlD3dOIvYcjjQKEO0qSyIX8c1O1r/WY0bGZtsumto25V9WE59e4eSOKo21KzGwL1ULu779aZKM5O2daRFCt+7H3Kk+mck4wwqHCcUHsJE1I+U34Vam79ZuLseWB1AKbogMtWg/9I69eSOxPtz+gOiY56sI2YSxepVkN0h0QxdEopZOz/9He+nC3OngwRaqFHOE6ofTpICC94s9sKdeKAFzCOOhUHHA7C/RfAqvtbv96qPM8T/4zukChGchAaUs1uu7VOB0Yf9v4T7uLEYbddHLXQQxwn1F5CBJQt1C2t30ysowZTopdK9BFqNgdVS03r1xOFWvUg+tDauCmXt/X6hjrpcNRO7EyMxV4pZtT23e4FoZs4Tqh9GEe9sSpMVW1t6zd1e52JKQo1QDDJobealKkHjjoaNp+fkWutzyECMtCkKmDdwYnleTFH3VX0YWfUWeKohR7hOKH26jBBvBxsgpC/qfWb9q24bFKto7adeXKUkjwyEbrneOwDNCMv3j5h6DnqrqIPyaiFXuJAoQ4SwEtD1IcnkuRUoskDXlIsz4s56iThbzV7Xg86E+0D1ZfXen1DnUiKnWzdWqcTM+ruRh+SUQs9w3FC7dEhmiMeWnQGvmhyRh1OyqhTjT46cNThXkYfMUct0Ucr7O3SldPsDk4szwun2JloXw1IRi30EMcJtY8gTRE3Lfjw6SSnklyel6pQ2066w4y6h52JtqO2ow+nCMhAk2rZWndo5agdsp1TvXKQOmqhlzhOqD06RAAvLWQYoU6sTU6u+ki1jjrmqJOjD7uOOqN3jtpnOWqnCMhAk47OxFYZtUPELjbXR4oZtVeEWugZjhNqrw4SxEuLzsBNNKlOuZ3yvFQccKdVH8qssy86E3vqqMNBWPaX1KKCmt1th9Y7jbQMeHGyo5aMWkgvjhNqjw4R0F5a8JkXEnPlpNnzGoNRdlU2tF1J3X7YvzL+e4dVHwEr9lC960zsrVDvXQqv/gT2Let62ff/AU9/sWef01+kuzPRKZ223Z2P2pOBuZVYL6Y9EIYkzhPqaDAWfQCtB70kzZ5XH9Dsq25su5J3fg9PXB3/3V5HMGnZSMgINaQn+ljxdyhf2/V6Wqx68eSqlHaXrTGf25cddX1NqmVr3cGJ5Xn2CaM7VR+JvwtCijhPqK3oo1kboQ76E8Q1afa8cBSikXYcsP8INFbEs8xQJ52JHkuoY52J3RHqZEedJEyv/BhK/9n1elrqrPalINT2fCXJJx0nka7ORI91+y2nCF2qjjqS6KhxTvuFQYOzhFrrWB2134o+As0J0UbS7HkhDdH2MuVQC6ChuSrhd4zzSVw+HGjHUXfjsrSz8rxwwLjAVATV/yEV6r6MKKLh+H0Sneaou5NRJ/4uCCniLKG2DsCA9tCM2albmhMEKSGjDkeihKOqA6G2BK/xsPV7gpNOFMNIyNRQQ0JnYk8cdX7bv42VBKYgqN1x1PayAScLtb/1Y18QCZn5X8A5nYndnutDhFroGc4SauvADuClRRunG2xJjD7iGfWRlhBRXOholEg0qUTPjjgaK81jYs6dKNqRoCnNgx52JiZl1IkOMmBdCXTHJSd3dna2rJMddapOsztEE+487pTyPPv/1FEI+eGxK1t3Ytu0EWoZ9CJ0D2cJtbXjB/HitzoTWwt1vDyvtjlIFIULTVMw6cC1hbmpovXvkOSog73sTLQddTvRR8xRpyLUtqNOJSaxhDrQTrWLU4g56j6elMmTASjnOWqA+gOw7WXY+27b5WIDXiSjFnqGs4Q6wVFHrY6jUEuCy0yY66O60RbqKE2BZKFOij4SxbKNo7aijx51JnZSR22Lbreijy4cdSQMQdupO9hRt9fJtvsdWP9Uz9cZDZnv3u11UEad8P81V5vH9k7M0RCg4qZAhFroJg4TarPjB7WXvPx866WkjNqaPc84alcHQm056Paij2CyUPemM9GelKmd8ryYUHfHUXexbKA+Yf0prHegaC+7fe8OePPWnq/TLqV0+5wjdInlhzGhbucEat/woqc3pxCGPI4U6gBehg8bBkAkkCBICY66pilkCbWmMZCU+dliHIs+muPTo4aSOhM9SRl1dx21csc7udqLPlLp9LMddfIQ9zbLJczP7eTOxPYGvDRX9+7kYnf8ujzOdNRNVoVRR0LdauIvyaiF7uEsobZ2/CAehg8rsF5KFOpwOxl1kqPWOh5vNCZk1NkjzPNERx0OtK366O7IRE9mfB2JAhJIg6NOvOdjMIWMetfbcGh918v1Ne1FH70V6lbRh0MG+4SD8druTqMPy2D0xAwIAk4T6pij9jFqeD4RrdC2sGrdqjyvpinemdiYKNSRYFxsGxMcdfbI+PPEZXs7MtGTOKFTBxl1ZxNHRaPgtyKNrjLqRKFOxVG/+C14+7ddL9fXdCTUoaaeD5+OOWqvczoTIwHItEozbaFu73uxDYZEH0IPcaRQB7WH0cMyaSYTbefL9nSmVqdfTVMQbUUfrRx1oqNJjD5yRrZ9P3EIeU86E0MtpmTMXkei04tdAuu2935MJFBvlmn1Nx1gO+9UlgUj7Ml3Xu8PkoU6Eo63PZUSxPaIhoxIuz3OKc8LB+Mdyc3W/Tjbc9SRkGTUQq9wpFAH8FKQ5SOAL77j27meNTKxpimI2+3BpZKiD1sU84rNwRMJtY4+WjnqXo5M9B8xg11i0UcHJ4zOLvkTxbcrEbNF1+VJLUYINAxMGZ+dTUesaWoTs/Wexh+RsBFppznqmFB3pzNRMup+IRyEp78E1TsHuiW9xllCHcuoveRneQioDFxhS3htF2Lt7LXNQXxeDy6irTsTbbEbPgnQppMn1NK1o+5JfhioN5e+7UUfiZfAneXJdkdiVmHqGXVecdcCHAkZwexvoY6ETfTk9pmroGg4LmLQ87LCmKN2SHme1sZYpCTUklEPCDW7YP2TsPPNgW5Jr+lSqJVS9ymlKpRSG9LemgRHPSzLS8CVhbLdmZ07J0QfPq8bT3JnYiuhxsQfoWbIHGYO9DYDXnoxhNxfb9arlFl3u9EHqTnqYeO6zqhb6swBnzuqa8GzBbrfhTppWH04kCTUPXXUiRl1PwhdOAAfPNJx/0I0DOj4/2nPK9NuZ6KU5w0I9rGVeNU6SEnFUT8AXJDmdhjCcUc9LMtLSGXgDlviFYs+LEfdFKQuZyoz1V4iTTXxdQSThLr+YHxCH192287EWHmedRB1p+rDjj6grdNLVahtR50/ruuOR/8Rc2LIyO26M3GghNrOpTP7WKij4YSMuh8c9fZX4dmvwsEP2n8/eZ6XLjsT0yjU1Tth+V19u84PA3bk1jIEhFprvQSo6Wq5PsFyz1F3BoU5PkLuTDxRy1HHhNqNPxShKRhh9/hPkKFCzKh4Mb4OuxbZFuraPebRmw3enKTyvGDvOhPt6APaEerEjLoTUfUnCLWOdF565q8zQu3LTd1Rh5r6NxNNFrCwvw8dtcca8NIPQt1kDZZq6WDXt78nO/pInIMl+WQbTXNnYulj8PL3nT2twEDQMrQcdUoopa5XSq1SSq2qrKzs2Uqsnf+JG88gL9NL2J2FJ5IUfbjc1Dab5fToWWxxTeP4mufjB4fdmVg4xTxWbTePMUfdUfTRzc5ErU30YQtScidXsAmyhsefd0TMURebR/8ReOs38ZK9RPxHILOge0Kd/DzdRJIcdSTZUfcio3b7rIipH6IDu4qjIzeWfOUQo50qn1hGnabORDt2+RA4xz5lKDnqVNFa3621Xqi1XlhUVNSzlViOevwoI3BRdyY+bTtq6+BUbmqajFAPz/bxevYFFAf3wL7l5n3bMWcXQu4YqNhsfvfmGFedWJcdDbWdPS9VtxP2m7+POWpf0oCXBvP50HlM4T9iDuAcs82q178Kb/3KXHq3t2x3o4/k5+kmJmDD4r83J0ZTvXDUseijHwa82Ad5R+WNsSw+r+17ySejWB11mky35AQAACAASURBVDoT7VGRHbn/oUosox6AEtU+xllVH/bcCZZ4Rj1Z+JKij7By8+c3jEueOCKb1XnnUOcqgMW/bD0q0Ztt4o+KTdbvWeDLib9vH+w97Uy0HW8so/a0jT7yRsefd7geO87IAeC1pdZ9E+2DD0yv9du/Nc4gK1VHnTgvSD8ON49NVJUo1NXmRAltt0VjJexb0fV67eijv8rz7KuAji6bw0nRRyLtCXWrIeTpEurazpcbasROtuKo+5aw3xyIVq209maToS3nYu3cz649xCsbD/M/l8zkmLH5uDPz+GfGp2DPO7BrcUyIl+xp5M2K7PiX5M22HLUlFDGhTqqjTrUz0RZC2zm2iT4a4446+cCt3GY6OcGIb2YB2hLqvKZ95vWmhPio9DFzIqrdHXfUkWDn9yRM/Mx+ddRWm5I7EwsmtG0XwNLb4eGPd96JCknleT0UumgE/no8rHuy62Xtq4AuHXVC9GFfnSWfjNLdmdg8hIW69LGOZ2W0I4+WIeColVL/BN4DpiulypRSX0hbaxKrMAA82WQRQGsdG5m49kADF88dy+dPmQxAboabf/FRGDYBlvyO6jrz5fy/xzaxrqkgvi7bUQca4J6Pwqr7rc/IwB+K8OZWa2fvsaP2JZXnNZn4RblbH7jRCDx4ibmfIpgTSVYBdSHj7MdFLQFvTnDUTQltszsToXOn3Cr6aCfv7i33ngdLbmv7esxRJ3Um5he33RZgKhZCzZ2fTKJR8/3brrSnjrqpEqq2wYHVXS/b0lVGbX3X9ncB8Suo5Fgq3Rn1UHbUy/5qbmbdHkPJUWutr9Jaj9Vae7XWJVrre9PWGnvuDBtfNlkqSCAUjglobUuUuSXDYovkZHioC7rgqLOJVmzhqfe2EtJubjp3Jq7hk+PrsoW6ejuUvR8vgnd7eXpNGV94pBSAQE0Za//2OfwNXeR9AessnZkYfVgiH40aEfXlWjFFgjjtXQaNh6DOcs7NNZA1nD2NCoBJ6pB5PTH6aK4ClPV5BT0Q6j521JEQlK1s/w7rbToTg0aoc0a2H9nU7TWPiSemZGxh7u181A3WtrXngOmMVB21JyN+VZY31jwmn4wiofRl1JFQXIiGolA3HjYn3/ZuUmFvl0D9oB8N6rDoIxC/fARcGWb60MamxtiGjuBi+pj45WZuhsdMypQ3FldLNdnRJlwZOXz93GkMGzcttlx10EPEnukM4mV7bh9byhvQuNAowpv/y7yKZyl/uYOztE1njtrOwTNywZdDNFEoN/7bPNqi0VAOeWPZWWuuGAqUdZAnRh9N1XDMJTD+RBh/QvyOMp11KHYm1EcOwDM3wC8KoSwFd5lM/QHjcJvaEdd2y/NqzBB+X05rodY6fsJqqqZDbGF2e2mJuKhuaGo7B3kq2DeSSEWobUfdYUadINT2LbZy7T6JpO1tRx92f0hfCnViR+1QE+qINeo1GobKLea1QAM8frXZrxK3xyDvUHSeUCc4am+mEaRDlTWx7DiCmxlj4h04ORkeguEo4ZxRAEzxVOLKMHnvmEnHxJa74r61bKhMcGJH9ptHt4+th82BFcVFTsAcxGO3PND5l2u/115GbTsqXw4N0QxeLd1pTibRCGx+zrzXeMj8v40VkD+OrTVJGa0t1Fqb54VT4AuvwqRTwWf9/5066vp4B16yUL/wTdjwtNmm5R0M6OiMWssFdybUtqMONBjhyi60hDpx0qyq+EmtuROhjjlqL+UNYYLBIGv39+By1j45NnUh1NFIQg1uR446oePbdtS5HXQepzOjTjyhp1uoK7bAi9+Glfe0PkEMFM3VxCY0O2QNnD6wBra8ADveMN+hfQwM8pOYs4Q60lqop44z4rtkw+7Yzp2Z4WVUXnyZnAyz8/szTHnbUZ4qlHUT1OlTp+LXxsXUhjzsabAuPaecGVufdvvYZgl1GPN+o84kM9IIK+7uuK2xzsTEAS/WAWgLqC+PyqAHX6SFHRWNptOjqRImnmo+/9AGQMOwcWyqTjp4bREM1EM0xOv7Ei7dYo66k0gj0Aj5Y9tfrrwU5nySqPIQrNnf8TrA7ODJl4117XR42iQ7arvTNHuEaXeiiNmxB3Qefdjb1e2lPqTwEKb8SA/ucN6Fo95w4AiL7niXxrpKYgLQVR21xxffZ/PszuNkoU7OqPvSUSdGZCmI0cHSuKh1l3VPGJF+8dsDM31uMvb3CXDY+p/sfbN2t7kasge+DfKc2llCneSoc0YfBcC2TR8QjRixGFOQi1IqtkxuhhHX/SEjDEWRw7Gz6MSRuRxQRuxb8HF/8ylw+b1Ep5wT+/u6ANQ1h8jL8BDWZr2lehpvcjx66e1mYpf28NcDKu5uEye0t4S6UWdQEfCSo/y4VvwN/n0DFC+A4641y1mdWtHcYtZVxg9ev8oyAh0OxAT7pV0hWoKWYPo6KHVLJNAQ73hMFOrmGmg8THnGFA5GC3j1vdU8/N6e9tcRDsKf5sPyO1u/bgusv65t5UkkqY46UaiT83o7foIUHbWHugB4iVB+pJOpYzvCdtT+unYzzTe3VLB2fx3bdu+L/w/dcdS2UCefGGOOOg0ZtX1Czx7ZsWvUOj6Q66n/By99r2ef1VAO+SVQfCxUbOzZOvoS+8rI7YvfIMMW6sMbzXa2hXqQD3pxnlAnZNSMnmkeWnayscxcao0rzG31J7ajfvuA+Vdc2prXA1BKUZ9ZAsCUMSMpPZJD3dRL+dua+DDyV7eanftjc8cSsRy1a8QUfui/Fq088OzX2h+tGKg3NbRWKWGr6MPKjlcfCtGoMyikgZkb/wBHnQuffwnsTk5LqMt1IQ0hF1FrGPtO1yQA/u/ppUQbzYFYrfPZVG65+FQ7EzPyzE9i1UfVNgC262IO6hFM8tbx02c38vKG8rbrqC8zorbt5dav2wcDGIFdfhdssiKd5AEvNdYUk/nj2mbUtuC7PO3HKDaxjNpHXUDjIdJtR90cDNNccyD+QjtXAy17V/G870dU77fyzuGTjVC3VzrYylFbGXX2iPanoO2rIeTL/gIPLWr9mn2CGzmtY6F++OPw4jfhSJn5Pmp29+zzG8rNVdqomSYGGWjse6JOOMk46sQ+j4OmOEAcdTpIctRkDSeaV8wsdxn3L90BdCzU/9oSIGo5YnzZsfdV0dHUk8s3zpthlltVxlvl3tj7L24yO/rlx5UQtjbHxGmzOEwh62Z+G/a+y8ZlL/DujiQhSRw+Dq2rEawDdeleP9qbwzTXATw6CMd/0ZxEbOd1YBUAaxtyAIW2rgRKw6bm+N21m9m1bw9ghHrDAcvd2YMsuupMjAl1gsOzRmqW+sdSwQhm5jQwb3wB3/nXOvZWJwlMnRWL7H8fQgnC2Eqoq0x51PtWTJRUnhe1h/APG982o67da5xg7ujOHXVCZ2JtSxRvD6KPP72+ne27dqLt6pl24o8RFcuZ49pD3v43zAuFU0yO394J0b5ycGcYsQaryicnfRn1zjfN7dUSv4umKnM/0MIp7Qu11ia3Xfev+GjXhvLW60iV+nKz7xZNN252oHNqO/qYerb53+sPJlRTWcdroWWKxFH3IUkZNYBrzGzOKDhMfbPZsSaMbD0SLNcS6p01AVp8heZFuwMBmHfVLWR/6b/MH29qqu98eyeVakTs/aawi8IcH8dNGI62HPWYiceQ5XXzUuQEAF5+9SV++EzSvQetCZmeX3uQk371BjtrAuZE8/jVsMEU4C/d52dEoRkOH8EFE0+2Gm11OlXvAF8e7+4PkpvhiXWCrrOEupB63indCsARlc96S6iPRM022r5rR8fbMtBgxDJZqCu3gjeHVbXZ+LPH4mo4yJ2fmU8gHOHRFftar8PucI0ETEmjTe3e+FVB7V5z0FZbbbGiEG2dTFz1B8CdQZ1rGHVhHzo5ox4+0TjRFKKP5oiiIays6KN7QrN8dw0jdC2hAmsOmCShDkWiZDeVATCxzvpf7fli2jvI7cjHkxG/CvTlmCiszcjEPsqoq3YA2uSvNs1VZi7z7BFGrJLdf0ut2VdDTQm5sjbf7dI/wOu/MC9Fwu2Ld6AxPvF+Q7mZC73ImB4qt3b/f3jndjOZfyo0VnZ+QmmqNPesnGAdV+Vr4/usTVeOOhplT1VT69v5ORBnCbV9s9hERs9iWONu/nS5qeA4avSwVm9PHJHNuIIsbv34bHJGWBMbeeNleCq7EM+4eRTlZTAqL4OapiBTpkyNvR/Cw9Gjc3G5FFmZxhm5R0zh1Gkj+ceqWg6pIo7Se9hX00xFgx8W/xr+9XnwH+Gg38tN//yAYCTKuvJmc1m55QXT6QI0RH1MHWfc8wY9haidZ3t8sbk9yC9mxe4aFk4ajrKy503RiQCU+JqoOGQu14+eMjnmqH/6wg6WROYwausj1FUdYuuhBhr8SbXFlqP2u3PYV36Yg3VWplu5BYqOZltFM65hJRAJUuxp5PRpRbyw9iDRqDnQ//LGdp547V3jQJUbdi+Jf0cN5VCy0PxuXRXQUG4+M+wH5eLVbXWEtDnxRfLH8Z2nNvD0hjqaGo6wao/lxGr3UpdRzIFgNjqF6KOyKUpYe3ApTUVd6sPi/aEImw7WUUQdFTnTzYtJlR97q5sYh1XxE7FydVuo28upY47ahx/rCi0jr228A9YQck9shsZl2zuoOtEayla1H7WEWuIilHjHkqZKU6OeNdy0KXlCqMSrH6sUFDAn2A8egbWPm99f+h48cFHbz138S7j7THMFGag3jnqULdQ9iD+2vgSbnu26rjkagTs/0v6gKpvGCjM3+9i55iS4911TOjpqZnyZvDHmRNred7ji7+jbj+Hyvy7mT69v6/7/0o84T6jtjhmbUbMgGiKn3jg25fa2fjsvk3d/cDbXnDQxPmQ7IfpIZFaxuRw/d86EmFBOGTOc06aZ59kZljMaPok/XjmfRfPHsS48gY9kG7FcvaeWplWPEt34LOEjB9l2xMUFs8aw7AdnM2qYEWFtT5cKfGTmRIZZd1NfFjmGww1xdxDMMq66OWs0OyoaOXHyCPBmE3Vnsgfzfxw3MkKhqsevMjlmwmi2HW7goff28Nzag6yY9m1ydTNv3vVNzv/jEq78+3KOtFhirTUEG9DeXNYeDtPcUMflf32LdfuqoXIrwcKjOVTvJ6vInBCoL+OSecUcPOJnzb5aFm+t4PevbcNVX0YwaxQUzye8cwnLdlTx+OvLAE1k7LEANOx8L76Bq3dCJID2ZPK7V7YStASs0j2aJdsqGVE4nCz8fOWR1VQeaUYfKeOpXW5WVrqorjhIONLBzIWWo65sjsQrc1r88c7VLthUXk9OpIEMFWa7mmReTHLU2w43UqLiubV2eczNHKB9N5bgqLdXm+dVQW/7E2ZZ0UdVc4iIVuyriotGNKrjpYa734Z7zoHVD7T9vJpd2JUokartZrQumPrz7JGm/BHaxh+2UBcvMI/zrjKPFZvM99Vw0Jxg9y03fSbJccb214xA25Oe5RebDkVvTveFWmvTRxIJdJ2TV203J6Gyleb3hkNtt2vjYSPU3iwYM9f0k+goTD49vkzWcDM/TvJVUcgP7/we1XiI4sBu1u53dp2184S6HUcNxEfBJQhhG+whvN72hXr++OF43YrzZo6JOYs/fuZEvnqWqS7B5YacUZCRS06Gh9uvmMcpp5xFUWAfBZ4gm7duIadpPy4ieGp3Uh/N4gcXziDT62bhVFNdstY7j5W5ZxPQXq49c3as429ZdBa7Ks1lvz8UobTO/J92Xn7ilELw5eLKH8ObP7wE3BnMGhYwQu0bzuxxw4hq+NmzGzl56gi+efUi1o76OJeGXuaa+cPZXtHAFx5YacQr1Aw6yrKyAPubPRRnhvhD9DeMvO9EaDhIReYkAEaMteKLmt1ctP/3TPVU8qsXN/HqP//CiaOiTPLUcECPpNQzF122iuvvWcwLS8wESv+tHEEYD67EifWrd0A4QAgP2ysa8WSY/3FFTQ7BSJTjpo3HTZRAoJmv/fmfqGiIA+5xFBeX4AvWct39K6lsCJgO3C3/ja/XKs871BghZAm1hwiH6tteFv/p9e189dE1rV77YF8do5Q5UDe2FJgJo5KF+tARSlQVEbdpc8hXYEaBQieOWtEUgsNNRjQfWlPdfkYdMUK9rqyOMG7qGlvwh8xJ5slV+1l0x7ss2VYZF8O3fm3Wkeg67awfePaNJfyn1OoYba6CnBHxKXU7EuqzfmIit2M/Z8zQtpeJlSBWbDEjdsE4epsjZfHXd71lHvPGmA70oqO7L9TN1fGTXuXmzpc9aH2HFZuNwN9zLrz6k9bLNFXGY8SS4+GI9b8mCnWm9T0mn2zXPR7LuOe6drGpvD52Ndktlv4R/n1j9/+umzhLqCOBeMeMzchppqLCHvLt6qTJtqPuQKi/dPpkXrjpNIryMkwVAsRHi4G5fCqMDztXSpEz6VgUmo+NqqVs7Rut1ldUNIpJI01ckWGJ0lNN8/hc9Wd5/vgHmT1+JIw7juDY41gZnc4/39/Hlx9ezSfvWsZOv3Hg2/35ZPvczBk3zJyUSo6nKD8TcoqYlNXMeF8T3ryi2LD5+eMLuPtzC/G4XSw47xo8KsqtJwT58ydn0bR/LTc8sppXPjAH13+3N1FYOIK8aB0n6rWM0iYH3onJwMdNtE5Qy+/Et+Ze/rfwZbxly/k1f+bv095nqq+GTc35/Hr7eLwqwpPnNPH3C007frvCT5XOI0cF8JNhIpLqHURCfupDbuaWDMNnjSzdHhjOyNwMxo0y96284/Kj+VSBaeM1V13LCTOPJl+1ULrnMNf/5Rn44GHzY2M56kONEbw+s394iFBe1/oyvyUY4Z53dvHi+vJ4vAJ8sK+Wmbmm0qe0NhOdW9Qm+qg4uI8MFSI85WwAmtzDjBODhMl96uKO0+r4XrK9ihZtsucHVlbQqDOJJjq/SJhIsJnKFk3pvjoiuHHrMOVL7kf/8yqyX/8BRdTy2Ip9xj1mFhgBufNk+N8ieOFbJs6wBLMydzrjogdZsm6nOSYaDxtHHRNq075lb/2X7Vs3GaHOyKdx/Bncc+LL7I6OMhNk7Uu4Etr2crzccH/CTIa73o491bsWmyd5VrxYNKP7GXVVQrxQsYUjzSF2V3VQYmobgKYKc/I4sr91m8GcbO0IcfwJ8ddHzTTbxOU1J85kR621qaAZO49mzzDmqF00BsKU1Vr7077lcMdJ8UqkPe/CczfDmoR90qb0MXNfxq5uo9dLnCXUYX9bR+32mgEqAMdcCiOP7vjv8zoX6myfh+n2qEZ7ov7EqGXiR+Do81v/0Zg5AJyeX86xehNNZBEdNRuABdMmJrTTrGfM8Zdxx7Wn8MmLP2Zen3wa3uvfwOXL5oV15awrqyMahWOONv9HOKeYk6eOxOt2wcd+B5ffY/4uZyQZgRpOGBUlZ/gYxg7L4vHrT+LhL5wQ60BVdk68fyUXNj3DS74fcGT7e/zmP+Zy8ZITpnPmnCmosB+lo/x7+m3cHPwaP1k/miyvm7FjS8z2tnLmjzS/xb2Tzcmo4NAyCsKV7I+OpKJgHtGsEcysX0rO1mcIDz+KhowxtHjN5fbu6GiqPaNZsXIFK7YfpCXq4Xvnz0BZJ90DeiQfnTkalzVQ59SJWXyyYBuMnM7Uo6YbRwg8cc3RTGu2yqrKVoLWPLpiL0u3mtLBfXUh8nPMd+u1hfrgB7FM9+WN5TQEwnjdiruXmPr3aFTzwb46FowwmfKOlhxCmUWmo+rAGmiqJhrV1JebaC1jzmUAVEdz4yWG/iPGbf3z06bUDaybTmTw6qbD4M4g4smmPhDltZ1NHKyo5LDl9su3rcStQzy2bzilZUeIKjdXuhcz+Z1vE9z/ARcEXubtzG+zfXMp0f2rYOalsOCzRmRmLoJV9xJ5+HKo2oHOH8f7LeOYrA5x5u7b4eHLjNvPH9vKUe84UMncxZ/n4BPfIFK7Fwomcs/S3dz64mbO/v1brDySBzpq+kxcHpMZg7n6s4S6wR/ig7f/QzhrJNGc0ShrumBtX7UWzTCZd2d9C8nYQu3NRlds4suPrGbRX5fGri4IB+AfZ5vc/MCauBasecB8duVWLv7df01fkT18PNFRA6CMCRs+yQi0Um0dddlKc/V34pfZ4ZnGPLeJYWLlr+//wzj+LS/CtldMdr/mQVj8q9b9B03VULXVRFsd3bKtj/Ckde3dJfHWWIlc85TZQAkDXdolr/OMuhX2qL3Ez1t0R9vlho2HzAJmufbQ7NpCRcF8Jk+eDxUbyMxNmJ1v3lUwfBJfO+GMNqtQSvHbT84F4MLZY3G7FKzaAbvgK4tORx81v+3n5hQZt9RUbXJ64KQpI1ovk1UAI6ebHc8qR3qg5AX2HPt9eAVOmjEJKq14wJfLpZdfw5b8XRx6bw/zSgpwuV3mhFWzC2ZcjNryArkHlxmBOrAKF3DC/HlccOZHcC29wIysjATwnP9r3phzJsOfmQi7dlKXUUxVoJlR0b3sDI9kki+TU6eNjB1o9RljuOa4cdBkDR5qrjYdP8d93vyebZz2rIIQ1xYfgAqgqZLSdaX8+N8HOdO1jVN9sL68ieOPHgaN4CHMsG3/ghd+wR2j/5cPsk+mosHPxBHZXDqvmL8u3sEND6+idH8dh+sDzJ3gh0NQoYdT5ypgVPlSkwePPJpn5t+Lp34/+IDiBdT6xrK5MYuWKpiN4u212/nLS3fxtMs4utsffZZr3Q0Md/t4Y/NhLhkxDrcq5+ErT2DMkn+TuW8D3316HfdddzxbV7zCWOCxQyXUVVWjMjzkR+rZkn0cvx/9Gyp2b+A/ru/yU/eDuAJ17MmcyTPqHPT0m5hXUsCm7SO4ed8/8O/Pojx3Jhv8o/iYt44L9LscmXoJlRMvZrWaTcEuP+cDtNTy0jtPcZPyc2xkHXVloykYP5NHlu/jpCmFnDB5BM3rS6D+A9aFJzKnwI+7ejugYNbHYcMzBIIBbnhwNX+sfZ93fHOZlNXCZA7TqDN5dEUVN5wxDCafBkDV2pfIOPbT5GW27jsCWFdWx+fvX8kVx4/n5rOnkVW13ewTE0+hcf963qswV3ivbDzEovnjjDAeWA1v3GJOADMvhfX/Qm94BgUoNLk1G3n8/WncfEIeoCHXctQFE4xouzzmqrx4Adrl4V+r9rPIk0dGS0LUsuFp08E442JWPvs616k1ZKkgm8rruWBaLmy1YretL5nSx9wxcOo3ze3OKrcYzQj741MpgKmKmnRK2+O4j3CWUN+0ulXFRiu6EmlIiD46WEcicz5lqglyRna+nFIw/kTGbf8XyqVpnnMdjJ0OK+5sfRumMbPNTwdcPLe49QvF88GXR9a42eBr52soWWiySuWKOc52KTkeNv3HVBoUzWB45fsMr7XqZe06aoBJp5GRkclPL57J9adPiW/O/HFGqM+71ZwYDn4AF/wG/vNlAI6bOw9G5sD0i6D0UXOgzfs0I7IzYtvuxGOPhWgY19rHmDZ1GqrBugy0ToL3fv1yKCiEHVbZ5I43zI4+1cQMZFv/X1MVM4PrOOgupjhykGdffJZxBadz/ZzxsBK+feEsTsqtgL0wLjvM3G1/BWDq4f9yF9Np8If5znlH8+kTJvDyhkMcW/YI13t3cvDTf2P+hvuJ5oyiJZDJ6/vhMzQQzStGVe+k5LUvc2rhXGgEho3Hc80T/OOhjVQ9soaXdRa7yw5wbcZ+/GEvXhXBvfk/vOWq5hSXpikYIff8H8O4TE7LGQl7S4iWNbF6627ufLuQWfuXUe4aQ417BKFwFHe2ByJwy5GLWFZTwXfOOxVVs4gzrZLOLy12sRMTc0Q1TMg/l2t8L1AYLGdp7XBqsyZAGDJUiP8LXsr9L+UAe8nCz+ZMeH75JoaV7wIP5KkWaNnDW5XHUdUY4PdXzOOMo4sgayG8/jyloRLCzUdYyA5acsezLDCTc0KP8LO/P0HJoXWM8tZxS9M8jmvZxmQPNPmK+L+XtzCzOJ/Tpi4gmDmS5S8/xr2lU3jqyycbAxKNmInHyteyeOswGgOzuPOtnTz7wQEez1uLz1PCqopCzq9fzKzRWdQF4PWV61g0dwzRNQ+BO9OUdALho84jsOlVckJHqC84hvy6zcx37eKxFfv4yoyRRrysOX5QCmZdFp8s7fxfcevz67n3qXWER+bymcZ9pvN0+CTY+B+iR51LVcjHisAEvuCLcu7wCjYdHA9b15o+nuIFZn77aAROvAFmfMwI9fbXTGev/4i54nH7iGSPYvOK13FN+QIzi5NvzdY3OEuo7V72njJiqnGidp1nZwyfBGf9KLX1LroDteo+2L2E7AWfNJeZY+bEe9J7QvEC+FFZx++ffDN88KjpIMnu5GQy/ngofcQ8/8Q/4Jnr4f2/m98zcuODcqaeFfuT0fkJ8dKsj5vtVTgZLvmT6Y0/6hx4/mZzeV8w3vr7s82l8cyPxysMrHzQVTjZHCjBRly1u+MnB0+m6fy1S8LsEZVrHzeX9rYDsU+W5WtRdXspOPMWWt76FROaN/GTK2/gZFc9rIRTpxfDYXMJ+zXPc4wKVrMv6xjOD5Vy3PVz2fDm4yw89kTycjN47dIQPHI/BOC4fbfBjtdQ5/yMf4xYSOOSFfjLX+fG4LeZEN3GL/g7kXCZOdF7M8mbMI+bPjGGrz22hlBWPp8qaiCnspTXs86iMFjODcPXUBbIJBz28cyNJzNvfMKV1ezLcS39A7eUrOQbL+ewJmMjDRPO5YLssTy/9iCujBzKsyaw7PAMLpozhq+ceRSUfQk2PEXEl8e3PnExCyePJKo1K3bXcMa0IoZt/iE8fzOXffQMPj7pDLj/t6xzHcP9O3KYMjKHh794ItvK6wk84SOvei0n+nYSLjkF9/7lKB1hSUU2U4tyOH2atZ2Hm8hu5rGnsHL1+yz0wNL6In6yJp93Mtx8oeo2JmXXoYtPpib0MXbuMznyyOJJHFWbyzefKOXqEycyoXk2H3Wt5Fv7Krn7uWdpWQAAC8RJREFU2dfZ7B/JqQfu4YrGR4ji4utEOW7mD8k47mpufXUPkYptfMBktnlKuJgwvz07j3Xbd/PJ9V9mz23TmdC8mb9ELuM8TynHsIub3lZcGyrmJNcRHqiawWXuKq4sruSufX42vfs8c4FX98FDy1bw/u4a4EyOKc7nxg3lLN9VwwMrDnHSlEL+uOt4rsx8iCWP3YZ3xvmc2niI722dxpoDy2mOmhLMc3J28fsDkwmEH8SXV4w6539iMVdo9hV4C8ab2PWd38U6l/Wq+2gadRzLanJZEFrDVQ+/y7+vHEXepOM6Pl57iLOEurdkF8J3OxkE0lNyi+DM75sfmy8v7fvPScSXDRf+Bh6/CoaVdLycnc0Nn2xOHte9YAbd7F9uBH60x7jm6Re2//fHfzH+fPSseJXN+BPNXXOGjY+354Yl8UwQ4gI7fKJpo8trMruJp5rXPVanrdvazew5Smp2mhOR/bt9IlpppjrPnnE2wZ2v8ImGMvILD8FWa8Id+56JwFnBxdRMvJAJZ90ED1xE0T8v5Kza3VD3NJz4ZXjtZ1B0jNkn1jxoTq4nXM+5GXkw438o3f45Nj61h0DxLFrUerIOLDP/s8VHZ45my/9egPp7ERxcBt4czr7u57B/Be4Xv8lRyoU+/9eUJIo0mO9gylksqniesrknU7itkZy5Z/OtyUczfngWnlkP4nUX8o1NIW44fSoul7lio/hY3HljuHBu3KxcOs+6Cpv/GWiuInfBp00sNeEjrPZ8Ctdm+N0V8xhXkMW4giw445uc+fZvrL/5mRlVuX85F59+IpfPWRCfI2fiKTDlTE4451McPuKHPc/TkDeNB65ZxNLVXs5c/z1cYT9c/CfuyptM1YYGeOE+3MOKueOiY1n013f585vbuWnMqeTXvsXrebcwYe1OHtPnc5l6g1f4CF/3X88/sv7Kadt+Ddt+zX+KZoC7kpKTr+HC2Yvg779n1q77mL53CVXkM7p5Byg45sIbeXT1Wo6peImtgZGMmLwA9m6mlKM5Kaea4/2b+GXuU8zd9AzvROdw41swsaiFq0+agM/j4oW15Xz5kTW4FHzyuBJ+c/lcbn9tOIvfW8hx1S9Q8c47NKgsdhWeSmVtgBbXCCKj57Lo8N+ZE32WjP3l/CZyNS8+GeIFnc0BPYIL/1KGx3WA//FO5bNqG3sYR5ku4lRVysMHx1LlHs156i3ua74Z/VAQ/f0NqPZu0dYLlO7qFkg9YOHChXrVqlVdLyh0zcFS04udXA1jE43AH2aZDqizrbvGhIOmM2TsvJ5/buk/TZZ3TQe3OQLjjP99A3xtNYw8CvYsNSeJyafBlY/Am7ea3vaP/c4sf+QA/GGmmVv7Uw/FK3iiEfjLsWbZ8SfCVY/Dm7eYkXOJfGsLHFoHj10B086HKx40WeMfZpl64OOug7VPQLjF5PpXPGjirX+cZa6eTvl6600X1UYoK7bAXaeYOOyyu1p/5ronTWncCdebE7a/Hl75oemTmHRq+9tlxxvwyCfMCai5Cm5aY672OiPQYGIu++TVBTVNQfZUN3HshOHxF7WGF74B65+Gm9eYS/TFv4Qb3jGDQtohsn817nvPJvjxe/DN/5R5sW6/qbYYZznDpiq4barZfh+9hQN1LWR53RS6/fDbKWgdoXzYAorrVkNGPoEvL+eNMhfj8lzMq33NRGqrHjBXh5ffC7M+AS99F1bdByj2fPwZRhQWkde8H6ZfgNYafyhKls8Nm5+H525m+6eXMm7Xk2S//XMAdpV8nKfGfodzZpdw7ISC2EnIH4qwdHsVc0qGtb5ytL6TsCeHd477E6eedzlHWkKU1/mZU+Qi+NKPiWx6gTXHfJ+3M06nrLaZS3M248ktZCPT8IcjlFS/x9Xbv8ET435MTe5RfGn7jaw+7R6OmlDMiIfPptk3kr8UfJebvvhFstuLM7tAKbVaa72w3fdEqD8EBBpNzODu5wukcMDcsSYhVonNPWHHI8nsX2lEI2mqgDadxbV7TO978QLj4n05MO5YM1Bh20sw4+J4aeX210zZ3LwrTcZetw9mXBI/Edh3b++M3e+YmMcectwbtDaOvm6vWd+5v0itj6WvCDSa2Kupyoj1qd/quKxVa7P9pp7d+f7z3t/MpGJFSVVX658yEdjk080UqMMnw7Rz2/59sMl0zs1cFP/eKjabum97aoWOsPeNpipY/jcj9J30B7VLNArL74ApZ3X8t10VLNjzpow71iwXCce32bZX0cUL0Nkjzcm/B4hQC4IgOJzOhNpZddSCIAhCG0SoBUEQHI4ItSAIgsMRoRYEQXA4ItSCIAgOR4RaEATB4YhQC4IgOBwRakEQBIeTlgEvSqlKYG+XC7bPSKAbk9z2G9Ku7uPUtkm7uoe0q/v0pG0TtdZF7b2RFqHuDUqpVR2NzhlIpF3dx6ltk3Z1D2lX9+nrtkn0IQiC4HBEqAVBEByOE4X67oFuQAdIu7qPU9sm7eoe0q7u06dtc1xGLQiCILTGiY5aEARBSECEWhAEweE4RqiVUhcopbYqpXYopX4wgO0Yr5RarJTapJTaqJT6uvX6z5VSB5RSpdbPRQPUvj1KqfVWG1ZZrxUqpV5TSm23Hod3tZ4+btP0hO1SqpSqV0p9YyC2mVLqPqVUhVJqQ8Jr7W4fZfiztc+tU0odOwBtu00ptcX6/H8rpQqs1ycppVoStt1dHa85Le3q8LtTSv3Q2mZblVLn93O7nkho0x6lVKn1en9ur440In37mdZ6wH8AN7ATmAL4gLXAzAFqy1jgWOt5HrANmAn8HPiOA7bVHmBk0mu/BX5gPf8B8JsB/i4PARMHYpsBpwPHAhu62j7ARcBLgAJOAlYMQNvOAzzW898ktG1S4nID0K52vzvrWFgLZACTrePW3V/tSnr/98DPBmB7daQRadvPnOKoTwB2aK13aa2DwOPAooFoiNa6XGu9xnreAGwGxnX+VwPOIuBB6/mDwMcHsC3nADu11j0dmdortNZLgJqklzvaPouAh7RhOVCglBrbn23TWr+qtQ5bvy4HOrnlfP+1qxMWAY9rrQNa693ADszx26/tUuZutlcA/0zHZ3dGJxqRtv3MKUI9Dtif8HsZDhBHpdQkYAGwwnrpa9aly339HS8koIFXlVKrlVLXW6+N1lqXW88PAaMHpmkAfJrWB48TtllH28dp+93/wzgvm8lKqQ+UUm8rpU4bgPa09905ZZudBhzWWm9PeK3ft1eSRqRtP3OKUDsOpVQu8DTwDa11PXAnMBWYD5RjLrsGglO11scCFwJfVUqdnvimNtdaA1JzqZTyAZcC/7Jecso2izGQ26czlFI/BsLAo9ZL5cAErfUC4FvAY0qp/H5skuO+uySuorUh6Pft1Y5GxOjr/cwpQn0AGJ/we4n12oCglPJivoBHtdbPAGitD2utI1rrKPAP0nS51xVa6wPWYwXwb6sdh+1LKeuxYiDahjl5rNFaH7ba6IhtRsfbxxH7nVLqOuBi4GrrAMeKFqqt56sxWfDR/dWmTr67Ad9mSikP8AngCfu1/t5e7WkEadzPnCLUK4FpSqnJliv7NPDcQDTEyr7uBTZrrW9PeD0xU7oM2JD8t/3QthylVJ79HNMRtQGzra61FrsWeLa/22bRyuU4YZtZdLR9ngM+Z/XKnwQcSbh07ReUUhcA3wMu1Vo3J7xepJRyW8+nANOAXf3Yro6+u+eATyulMpRSk612vd9f7bI4F9iitS6zX+jP7dWRRpDO/aw/eklT7Em9CNN7uhP48QC241TMJcs6oNT6uQh4GFhvvf4cMHYA2jYF0+O+FthobydgBPAGsB14HSgcgLblANXAsITX+n2bYU4U5UAIkwV+oaPtg+mFv8Pa59YDCwegbTsw+aW9r91lLXu59R2XAmuAS/q5XR1+d8CPrW22FbiwP9tlvf4A8OWkZftze3WkEWnbz2QIuSAIgsNxSvQhCIIgdIAItSAIgsMRoRYEQXA4ItSCIAgOR4RaEATB4YhQC4IgOBwRakEQBIfz/wF6NMwe7KdyewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-hmR7PWMiim"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(units=26,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=13,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NlFaBCgM3yr"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103182,
     "status": "ok",
     "timestamp": 1591776187524,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "vo9EyPtLMvis",
    "outputId": "18aafa14-cf3e-4612-ad70-23864f261d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 41.3800 - val_loss: 2.3951\n",
      "Epoch 2/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 8.1204 - val_loss: 0.8741\n",
      "Epoch 3/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 2.6048 - val_loss: 0.6826\n",
      "Epoch 4/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 1.3425 - val_loss: 0.6513\n",
      "Epoch 5/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 1.0546 - val_loss: 0.6288\n",
      "Epoch 6/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 1.0716 - val_loss: 0.6144\n",
      "Epoch 7/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.9048 - val_loss: 0.6049\n",
      "Epoch 8/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.7582 - val_loss: 0.5981\n",
      "Epoch 9/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6913 - val_loss: 0.5848\n",
      "Epoch 10/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7900 - val_loss: 0.5742\n",
      "Epoch 11/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.7196 - val_loss: 0.5751\n",
      "Epoch 12/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6556 - val_loss: 0.5612\n",
      "Epoch 13/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.6215 - val_loss: 0.5499\n",
      "Epoch 14/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5897 - val_loss: 0.5550\n",
      "Epoch 15/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5811 - val_loss: 0.5507\n",
      "Epoch 16/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5613 - val_loss: 0.5531\n",
      "Epoch 17/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5786 - val_loss: 0.5430\n",
      "Epoch 18/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5678 - val_loss: 0.5386\n",
      "Epoch 19/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5492 - val_loss: 0.5374\n",
      "Epoch 20/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5573 - val_loss: 0.5488\n",
      "Epoch 21/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5482 - val_loss: 0.5406\n",
      "Epoch 22/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5457 - val_loss: 0.5467\n",
      "Epoch 23/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5536 - val_loss: 0.5353\n",
      "Epoch 24/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5396 - val_loss: 0.5302\n",
      "Epoch 25/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5505 - val_loss: 0.5275\n",
      "Epoch 26/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5403 - val_loss: 0.5297\n",
      "Epoch 27/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5317 - val_loss: 0.5257\n",
      "Epoch 28/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5332 - val_loss: 0.5288\n",
      "Epoch 29/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5409 - val_loss: 0.5209\n",
      "Epoch 30/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5282 - val_loss: 0.5375\n",
      "Epoch 31/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5478 - val_loss: 0.5184\n",
      "Epoch 32/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5343 - val_loss: 0.5182\n",
      "Epoch 33/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.5277 - val_loss: 0.5186\n",
      "Epoch 34/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5255 - val_loss: 0.5241\n",
      "Epoch 35/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5428 - val_loss: 0.5132\n",
      "Epoch 36/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5298 - val_loss: 0.5079\n",
      "Epoch 37/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5210 - val_loss: 0.5184\n",
      "Epoch 38/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5256 - val_loss: 0.5167\n",
      "Epoch 39/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5179 - val_loss: 0.5071\n",
      "Epoch 40/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5159 - val_loss: 0.5119\n",
      "Epoch 41/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5184 - val_loss: 0.5075\n",
      "Epoch 42/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5087 - val_loss: 0.4989\n",
      "Epoch 43/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.4980\n",
      "Epoch 44/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5090 - val_loss: 0.5018\n",
      "Epoch 45/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4987 - val_loss: 0.5015\n",
      "Epoch 46/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5125 - val_loss: 0.5066\n",
      "Epoch 47/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5136 - val_loss: 0.4986\n",
      "Epoch 48/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5041 - val_loss: 0.4941\n",
      "Epoch 49/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5103 - val_loss: 0.5015\n",
      "Epoch 50/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5015 - val_loss: 0.4927\n",
      "Epoch 51/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.5038 - val_loss: 0.4883\n",
      "Epoch 52/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4995 - val_loss: 0.4868\n",
      "Epoch 53/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4933 - val_loss: 0.4835\n",
      "Epoch 54/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4880 - val_loss: 0.4791\n",
      "Epoch 55/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4861 - val_loss: 0.4801\n",
      "Epoch 56/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4848 - val_loss: 0.4641\n",
      "Epoch 57/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4831 - val_loss: 0.4695\n",
      "Epoch 58/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4807 - val_loss: 0.4756\n",
      "Epoch 59/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4768 - val_loss: 0.4706\n",
      "Epoch 60/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4727 - val_loss: 0.4691\n",
      "Epoch 61/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4750 - val_loss: 0.4670\n",
      "Epoch 62/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4793 - val_loss: 0.4623\n",
      "Epoch 63/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4702 - val_loss: 0.4642\n",
      "Epoch 64/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4665 - val_loss: 0.4664\n",
      "Epoch 65/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4693 - val_loss: 0.4645\n",
      "Epoch 66/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4671 - val_loss: 0.4535\n",
      "Epoch 67/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4663 - val_loss: 0.4547\n",
      "Epoch 68/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4646 - val_loss: 0.4586\n",
      "Epoch 69/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4739 - val_loss: 0.4610\n",
      "Epoch 70/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4678 - val_loss: 0.4582\n",
      "Epoch 71/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4648 - val_loss: 0.5825\n",
      "Epoch 72/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4625 - val_loss: 0.4545\n",
      "Epoch 73/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4666 - val_loss: 0.4585\n",
      "Epoch 74/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4597 - val_loss: 0.4455\n",
      "Epoch 75/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4626 - val_loss: 0.4576\n",
      "Epoch 76/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4637 - val_loss: 0.4591\n",
      "Epoch 77/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4612 - val_loss: 0.4682\n",
      "Epoch 78/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4610 - val_loss: 0.4595\n",
      "Epoch 79/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4594 - val_loss: 0.4488\n",
      "Epoch 80/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4589 - val_loss: 0.4488\n",
      "Epoch 81/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4606 - val_loss: 0.4576\n",
      "Epoch 82/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4569 - val_loss: 0.4495\n",
      "Epoch 83/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4548 - val_loss: 0.4435\n",
      "Epoch 84/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4576 - val_loss: 0.4586\n",
      "Epoch 85/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4556 - val_loss: 0.4494\n",
      "Epoch 86/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4549 - val_loss: 0.4349\n",
      "Epoch 87/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4505 - val_loss: 0.4499\n",
      "Epoch 88/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4542 - val_loss: 0.4457\n",
      "Epoch 89/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4545 - val_loss: 0.4483\n",
      "Epoch 90/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 0.4505\n",
      "Epoch 91/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4565 - val_loss: 0.4503\n",
      "Epoch 92/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4625 - val_loss: 0.4477\n",
      "Epoch 93/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4580 - val_loss: 0.4348\n",
      "Epoch 94/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 0.4499\n",
      "Epoch 95/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4546 - val_loss: 0.4498\n",
      "Epoch 96/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4570 - val_loss: 0.4394\n",
      "Epoch 97/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4559 - val_loss: 0.4489\n",
      "Epoch 98/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4552 - val_loss: 0.4474\n",
      "Epoch 99/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4506 - val_loss: 0.4450\n",
      "Epoch 100/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4516 - val_loss: 0.4322\n",
      "Epoch 101/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4526 - val_loss: 0.4364\n",
      "Epoch 102/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4527 - val_loss: 0.4390\n",
      "Epoch 103/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4492 - val_loss: 0.4452\n",
      "Epoch 104/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4494 - val_loss: 0.4422\n",
      "Epoch 105/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4555 - val_loss: 0.4399\n",
      "Epoch 106/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4529 - val_loss: 0.4422\n",
      "Epoch 107/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4507 - val_loss: 0.4324\n",
      "Epoch 108/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4513 - val_loss: 0.4385\n",
      "Epoch 109/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4512 - val_loss: 0.4750\n",
      "Epoch 110/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4496 - val_loss: 0.4359\n",
      "Epoch 111/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4532 - val_loss: 0.4409\n",
      "Epoch 112/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4551 - val_loss: 0.4419\n",
      "Epoch 113/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4441 - val_loss: 0.4383\n",
      "Epoch 114/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4510 - val_loss: 0.4408\n",
      "Epoch 115/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4527 - val_loss: 0.4433\n",
      "Epoch 116/200\n",
      "166/166 [==============================] - 1s 6ms/step - loss: 0.4509 - val_loss: 0.4465\n",
      "Epoch 117/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4502 - val_loss: 0.4476\n",
      "Epoch 118/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4583 - val_loss: 0.4450\n",
      "Epoch 119/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4525 - val_loss: 0.4486\n",
      "Epoch 120/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4507 - val_loss: 0.4415\n",
      "Epoch 121/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4546 - val_loss: 0.4411\n",
      "Epoch 122/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4533 - val_loss: 0.4440\n",
      "Epoch 123/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4452 - val_loss: 0.4276\n",
      "Epoch 124/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4511 - val_loss: 0.4414\n",
      "Epoch 125/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4556 - val_loss: 0.4475\n",
      "Epoch 126/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4540 - val_loss: 0.4395\n",
      "Epoch 127/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4528 - val_loss: 0.4473\n",
      "Epoch 128/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4540 - val_loss: 0.4347\n",
      "Epoch 129/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4512 - val_loss: 0.4427\n",
      "Epoch 130/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4474 - val_loss: 0.4341\n",
      "Epoch 131/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4540 - val_loss: 0.4388\n",
      "Epoch 132/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4471 - val_loss: 0.4445\n",
      "Epoch 133/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4486 - val_loss: 0.4392\n",
      "Epoch 134/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4469 - val_loss: 0.4295\n",
      "Epoch 135/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4492 - val_loss: 0.4286\n",
      "Epoch 136/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4513 - val_loss: 0.4418\n",
      "Epoch 137/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4502 - val_loss: 0.4362\n",
      "Epoch 138/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4453 - val_loss: 0.4373\n",
      "Epoch 139/200\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.4451 - val_loss: 0.4328\n",
      "Epoch 140/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4525 - val_loss: 0.4301\n",
      "Epoch 141/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4501 - val_loss: 0.4370\n",
      "Epoch 142/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4465 - val_loss: 0.4397\n",
      "Epoch 143/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4484 - val_loss: 0.4361\n",
      "Epoch 144/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4489 - val_loss: 0.4385\n",
      "Epoch 145/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4420 - val_loss: 0.4308\n",
      "Epoch 146/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4512 - val_loss: 0.4372\n",
      "Epoch 147/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4516 - val_loss: 0.4290\n",
      "Epoch 148/200\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 0.4462 - val_loss: 0.4430\n",
      "Epoch 00148: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f055f585c50>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=200,\n",
    "          validation_data=(x_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1478,
     "status": "ok",
     "timestamp": 1591776193854,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "zfV751A9NcTu",
    "outputId": "031291f2-893e-437d-d340-b04f9cb76586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0576317f60>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZdy8-wLNtkJ"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1521,
     "status": "ok",
     "timestamp": 1591776203166,
     "user": {
      "displayName": "Adithya G",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj6cbWczXXGiM5lu4hP32ar8AOfyWtkP6J6ukM9=s64",
      "userId": "17561207832701819207"
     },
     "user_tz": -330
    },
    "id": "g4DPsgDnN6sq",
    "outputId": "11c936c8-2708-4051-de62-2e9390119bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87      1279\n",
      "           1       0.77      0.34      0.47       482\n",
      "\n",
      "    accuracy                           0.79      1761\n",
      "   macro avg       0.78      0.65      0.67      1761\n",
      "weighted avg       0.79      0.79      0.76      1761\n",
      "\n",
      "[[1230   49]\n",
      " [ 318  164]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOXwYsQEYdIJ+tXPat6nMTw",
   "mount_file_id": "11M1zF6H3sMPQZ0R--3atDasVb0tPHFeQ",
   "name": "DeepLearning-Telecom_Churn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
